{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c813506d-ff2a-45a2-9c48-bdc29b86c296",
   "metadata": {},
   "source": [
    "## Denovo design of tecnetium labeled proteins using Technetium-carbonyl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aac778-3432-41bd-a2ab-915dce4e8cae",
   "metadata": {},
   "source": [
    "# \n",
    "This script needs to be launched from the virtual enviroment created from the diffusion.yml file. This script covers the entire pipeline of creating new backbones, generating sequences with ProteinMPNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12c93e-6ed7-46ed-900f-734ef36833ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import getpass\n",
    "import subprocess\n",
    "import time\n",
    "import importlib\n",
    "from shutil import copy2\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### Path to this cloned GitHub repo:\n",
    "SCRIPT_DIR = os.getcwd()\n",
    "#SCRIPT_DIR = os.path.dirname(\"/home/ayobami/Documents/applications/heme_binder_diffusion\")  # edit this to the GitHub repo path. Throws an error by default.\n",
    "assert os.path.exists(SCRIPT_DIR)\n",
    "sys.path.append(SCRIPT_DIR+\"/scripts/utils\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6bdec3-70f9-433b-8e54-6c76759f2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac7964-8b5d-4852-a060-633bc0e00833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "diffusion_script = \"/home/projects/protein_design/rf_diffusion_all_atom/run_inference.py\"  # edit this\n",
    "inpaint_script = \"/home/projects/protein_design/RFDesign/inpainting/inpaint.py\"  # edit this if needed\n",
    "proteinMPNN_script = f\"{SCRIPT_DIR}/lib/LigandMPNN/run.py\"  # from submodule\n",
    "AF2_script = f\"{SCRIPT_DIR}/scripts/af2/af2.py\"  # from submodule\n",
    "\n",
    "### Use active Python interpreter instead of hardcoded paths\n",
    "PYTHON = {\n",
    "    \"diffusion\": sys.executable,\n",
    "    \"af2\": sys.executable,\n",
    "    \"proteinMPNN\": sys.executable,\n",
    "    \"general\": sys.executable\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb52b6-1c07-45ef-bb62-28f6d7fb83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"ligand_diffusion\"\n",
    "\n",
    "### Path where the jobs will be run and outputs dumped\n",
    "WDIR = \"/home/projects/protein_design/tc_binder_diffusion\"\n",
    "\n",
    "if not os.path.exists(WDIR):\n",
    "    os.makedirs(WDIR, exist_ok=True)\n",
    "\n",
    "print(f\"Working directory: {WDIR}\")\n",
    "\n",
    "USE_GPU_for_AF2 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334561d6-1026-4f37-ae10-f83b4c2013fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ligand information\n",
    "params = [f\"{SCRIPT_DIR}/theozyme/TCO/TC_CARBONYL.params\"]  # Rosetta params file(s)\n",
    "LIGAND = \"TCO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795857b6-edc1-4994-9f1b-fb1b82eaff62",
   "metadata": {},
   "outputs": [],
   "source": [
    ".## Kindly ensure only the intended pdb files are present in this directory\n",
    "diffusion_inputs = glob.glob(f\"{SCRIPT_DIR}/input/input.pdb\")\n",
    "print(f\"Found {len(diffusion_inputs)} PDB files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc3ddc-04c2-4a95-9c4b-d577f60033ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DIFFUSION_DIR = f\"{WDIR}/0_diffusion\"\n",
    "if not os.path.exists(DIFFUSION_DIR):\n",
    "    os.makedirs(DIFFUSION_DIR, exist_ok=False)\n",
    "\n",
    "os.chdir(DIFFUSION_DIR)\n",
    "\n",
    "N_designs = 101\n",
    "T_steps = 50\n",
    "\n",
    "# Absolute path to your paper weights:\n",
    "CKPT_PATH = \"/home/projects/protein_design/rf_diffusion_all_atom/RFDiffusionAA_paper_weights.pt\"\n",
    "\n",
    "config = f\"\"\"\n",
    "defaults:\n",
    "  - aa\n",
    "  - _self_\n",
    "\n",
    "diffuser:\n",
    "  T: {T_steps}\n",
    "\n",
    "inference:\n",
    "  num_designs: {N_designs}\n",
    "  model_runner: NRBStyleSelfCond\n",
    "  ligand: '{LIGAND}'\n",
    "  ckpt_path: '{CKPT_PATH}'   # ✅ use absolute path!\n",
    "\n",
    "model:\n",
    "  freeze_track_motif: True\n",
    "contigmap:\n",
    "  contigs: [\"30-100,A1-3,30-100\"]\n",
    "  inpaint_str: null\n",
    "  length: \"100-150\"\n",
    "  \n",
    "potentials:\n",
    "  guiding_potentials: [\"type:ligand_ncontacts,weight:1\"]\n",
    "  guide_scale: 2\n",
    "  guide_decay: cubic\n",
    "\"\"\"\n",
    "\n",
    "estimated_time = 3.5 * T_steps * N_designs\n",
    "\n",
    "print(f\"Estimated time to produce {N_designs} designs = {estimated_time/60:.0f} minutes\")\n",
    "with open(\"config.yaml\", \"w\") as file:\n",
    "    file.write(config)\n",
    "\n",
    "print(f\"Wrote config file to {os.path.realpath('config.yaml')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e050ab-a160-4544-a5ff-083dc17a6b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Setup commands to run diffusion directly\n",
    "commands_diffusion = []\n",
    "diffusion_rundirs = []\n",
    "\n",
    "for p in diffusion_inputs:\n",
    "    pdbname = os.path.basename(p).replace(\".pdb\", \"\")\n",
    "    os.makedirs(pdbname, exist_ok=True)\n",
    "    \n",
    "    cmd = f\"cd {pdbname} && {PYTHON['diffusion']} {diffusion_script} --config-dir=../ \" \\\n",
    "          f\"--config-name=config.yaml inference.input_pdb={p} \" \\\n",
    "          f\"inference.output_prefix='./out/{pdbname}_dif'\"\n",
    "    \n",
    "    commands_diffusion.append(cmd)\n",
    "    diffusion_rundirs.append(pdbname)\n",
    "\n",
    "print(f\"Running {len(commands_diffusion)} diffusion jobs locally\")\n",
    "\n",
    "# Run each command sequentially and capture output\n",
    "for cmd in commands_diffusion:\n",
    "    print(f\"\\nRunning:\\n{cmd}\\n\")\n",
    "    result = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(\"STDOUT:\\n\", result.stdout.decode())\n",
    "    print(\"STDERR:\\n\", result.stderr.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c6392b-d7ed-4703-a2ce-3e948756c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you're done with diffusion and happy with the outputs then mark it as done\n",
    "DIFFUSION_DIR = f\"{WDIR}/0_diffusion\"\n",
    "os.chdir(DIFFUSION_DIR)\n",
    "\n",
    "if not os.path.exists(DIFFUSION_DIR+\"/.done\"):\n",
    "    with open(f\"{DIFFUSION_DIR}/.done\", \"w\") as file:\n",
    "        file.write(f\"Run user: {username}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a044d0d-ea0f-43f1-a343-4351df0650ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install blosc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e0c7b-f1b3-4c1a-984e-ecc3dd68eaea",
   "metadata": {},
   "source": [
    "It will be nice to manually inspect the backbones generated. Kindly note that in addition to predicting bacbone coordinates, rf diffusion generates empty coordinates of ala side chains which will be a problem for pyrosetta and alphafold2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8629f0af-5931-4b2b-9b24-68718c5615b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is just an evaluation step for generated backbones. The process_diffusion_outputs.py file will need fixing after removing zero coordinate backbones\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "# Paths\n",
    "analysis_script = f\"{SCRIPT_DIR}/scripts/diffusion_analysis/process_diffusion_outputs.py\"\n",
    "\n",
    "# Get all output PDBs from diffusion directories\n",
    "diffusion_outputs = []\n",
    "for d in diffusion_rundirs:\n",
    "    diffusion_outputs += glob.glob(f\"{d}/out/*.pdb\")\n",
    "\n",
    "# Get all reference PDBs (this fixes the *.pdb issue!)\n",
    "ref_pdbs = glob.glob(f\"{SCRIPT_DIR}/input/*.pdb\")\n",
    "\n",
    "# Build command dictionary\n",
    "dif_analysis_cmd_dict = {\n",
    "    \"--pdb\": diffusion_outputs,\n",
    "    \"--ref\": ref_pdbs,\n",
    "    \"--params\": params,\n",
    "    \"--term_limit\": \"15.0\",\n",
    "    \"--SASA_limit\": \"0.3\",\n",
    "    \"--loop_limit\": \"0.8\",\n",
    "    \"--ref_catres\": [\"A3\"],\n",
    "    \"--rethread\": True,\n",
    "    \"--fix\": True,\n",
    "    \"--exclude_clash_atoms\": [\"O1\", \"O2\", \"O3\"],\n",
    "    \"--ligand_exposed_atoms\": [\"C1\", \"C2\", \"C3\"],\n",
    "    \"--exposed_atom_SASA\": \"10.0\",\n",
    "    \"--longest_helix\": \"30\",\n",
    "    \"--rog\": \"30.0\",\n",
    "    \"--traj\": \"5/30\",\n",
    "    \"--analyze\": False,\n",
    "    \"--nproc\": \"1\"\n",
    "}\n",
    "\n",
    "# Build full shell command\n",
    "analysis_command = f\"{PYTHON['general']} {analysis_script}\"\n",
    "for k, val in dif_analysis_cmd_dict.items():\n",
    "    if val is not None:\n",
    "        if isinstance(val, list):\n",
    "            analysis_command += f\" {k} \" + \" \".join(val)\n",
    "        elif isinstance(val, bool):\n",
    "            if val:  # only if True\n",
    "                analysis_command += f\" {k}\"\n",
    "        else:\n",
    "            analysis_command += f\" {k} {val}\"\n",
    "print(\"Final command to run:\\n\", analysis_command)\n",
    "\n",
    "# Run locally if small\n",
    "if len(diffusion_outputs) < 100:\n",
    "    p = subprocess.Popen(analysis_command, shell=True)\n",
    "    output, err = p.communicate()\n",
    "else:\n",
    "    submit_script = \"submit_diffusion_analysis.sh\"\n",
    "    utils.create_slurm_submit_script(\n",
    "        filename=submit_script,\n",
    "        name=\"diffusion_analysis\",\n",
    "        mem=\"8g\",\n",
    "        N_cores=dif_analysis_cmd_dict[\"--nproc\"],\n",
    "        time=\"0:20:00\",\n",
    "        email=EMAIL,\n",
    "        command=analysis_command,\n",
    "        outfile_name=\"output_analysis\"\n",
    "    )\n",
    "\n",
    "# Load results\n",
    "diffused_backbones_good = glob.glob(f\"{DIFFUSION_DIR}/filtered_structures/*.pdb\")\n",
    "dif_analysis_df = pd.read_csv(f\"{DIFFUSION_DIR}/diffusion_analysis.sc\", header=0, sep=r\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1940c574-84c5-4f5b-bb04-f049cf446c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This could help debug the previous cell using just a single pdb\n",
    "!python3.9 /home/projects/protein_design/binder_diffusion/scripts/diffusion_analysis/ppprocess_diffusion_outputs.py \\\n",
    "--pdb /home/projects/protein_design/binder_diffusion/0_diffusion/5abc_6debug/out/5abc_6debug_dif_2.pdb \\\n",
    "--ref /home/projects/protein_design/binder_diffusion/input/5abc_6debug.pdb \\\n",
    "--params /home/projects/protein_design/binder_diffusion/theozyme/TCO/TC_CARBONYL.params \\\n",
    "--term_limit 999.0 \\\n",
    "--SASA_limit 0.0 \\\n",
    "--loop_limit 0.0 \\\n",
    "--ref_catres A3 \\\n",
    "--rethread \\\n",
    "--fix \\\n",
    "--exclude_clash_atoms O1 O2 O3 \\\n",
    "--ligand_exposed_atoms C1 C2 C3 \\\n",
    "--exposed_atom_SASA 0.0 \\\n",
    "--longest_helix 999 \\\n",
    "--rog 999.0 \\\n",
    "--analyze \\\n",
    "--nproc 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b81abe-9fee-4c28-b127-6d808aada5b6",
   "metadata": {},
   "source": [
    "## ProteinMPNN\n",
    "The goal here is to design various sequences for the generated backbones.Little consideration is payed to ligand information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614f987-a45d-45df-a0f1-63931d48cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "# 1Grab the good backbones\n",
    "diffused_backbones_good = glob.glob(f\"{DIFFUSION_DIR}/filtered_structures/*.pdb\")\n",
    "assert len(diffused_backbones_good) > 0, \"No good backbones found!\"\n",
    "\n",
    "# Setup ProteinMPNN working dir\n",
    "os.chdir(WDIR)\n",
    "MPNN_DIR = f\"{WDIR}/1_proteinmpnn\"\n",
    "os.makedirs(MPNN_DIR, exist_ok=True)\n",
    "os.chdir(MPNN_DIR)\n",
    "\n",
    "# Mask JSON: parse TRB files for motif residues\n",
    "mask_json_cmd = f\"{PYTHON['general']} {SCRIPT_DIR}/scripts/design/make_maskdict_from_trb.py --out masked_pos.jsonl --trb\"\n",
    "for d in diffused_backbones_good:\n",
    "    mask_json_cmd += \" \" + d.replace(\".pdb\", \".trb\")\n",
    "\n",
    "print(\"Running mask command:\")\n",
    "print(mask_json_cmd)\n",
    "\n",
    "result = subprocess.run(mask_json_cmd, shell=True)\n",
    "assert os.path.exists(\"masked_pos.jsonl\"), \"Failed to create masked positions JSONL file\"\n",
    "\n",
    "# Prepare ProteinMPNN runs for multiple temps\n",
    "MPNN_temperatures = [0.1, 0.2, 0.3]\n",
    "MPNN_outputs_per_temperature = 5\n",
    "MPNN_omit_AAs = \"CM\"\n",
    "\n",
    "commands_mpnn = []\n",
    "\n",
    "for T in MPNN_temperatures:\n",
    "    for f in diffused_backbones_good:\n",
    "        cmd = (\n",
    "            f\"{PYTHON['proteinMPNN']} {proteinMPNN_script} \"\n",
    "            f\"--model_type protein_mpnn --ligand_mpnn_use_atom_context 0 \"\n",
    "            f\"--fixed_residues_multi masked_pos.jsonl --out_folder ./ \"\n",
    "            f\"--number_of_batches {MPNN_outputs_per_temperature} --temperature {T} \"\n",
    "            f\"--omit_AA {MPNN_omit_AAs} --pdb_path {f} \"\n",
    "            f\"--checkpoint_protein_mpnn {SCRIPT_DIR}/lib/LigandMPNN/model_params/proteinmpnn_v_48_020.pt\"\n",
    "        )\n",
    "        commands_mpnn.append(cmd)\n",
    "\n",
    "print(f\"\\nPrepared {len(commands_mpnn)} local ProteinMPNN jobs\")\n",
    "print(\"Example command:\\n\", commands_mpnn[0])\n",
    "\n",
    "# Run them locally, one-by-one\n",
    "for cmd in commands_mpnn:\n",
    "    print(\"\\nRunning:\")\n",
    "    print(cmd)\n",
    "    result = subprocess.run(cmd, shell=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"⚠️  Warning: A command failed with return code {result.returncode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126d5da-c2e9-48c3-958c-37603701fda7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

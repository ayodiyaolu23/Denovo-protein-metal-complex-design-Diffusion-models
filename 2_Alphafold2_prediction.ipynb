{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffce94f8-ed8e-4618-8729-9b93e1cd59c6",
   "metadata": {},
   "source": [
    "## Denovo design of technetium labeled proteins-Prediction of alphafold2\n",
    "This script details the execution of Alphafold2 step after initial proteinMPNN runs. It also lists potential analysis to screen designed proteins. This script should be executed after installing the dependencies in the \"mlfold.yml\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748826fc-4c1f-4b3d-b0b5-31e4bf37e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import getpass\n",
    "import subprocess\n",
    "import time\n",
    "import importlib\n",
    "from shutil import copy2\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### Path to this cloned GitHub repo:\n",
    "SCRIPT_DIR = os.getcwd()\n",
    "assert os.path.exists(SCRIPT_DIR)\n",
    "sys.path.append(SCRIPT_DIR+\"/scripts/utils\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1432c510-44f6-45e7-8248-169b4ed81d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(WDIR)\n",
    "\n",
    "AF2_DIR = f\"{WDIR}/2_af2\"\n",
    "os.makedirs(AF2_DIR, exist_ok=True)\n",
    "os.chdir(AF2_DIR)\n",
    "\n",
    "### First collecting MPNN outputs and creating FASTA files for AF2 input\n",
    "mpnn_fasta = utils.parse_fasta_files(glob.glob(f\"{MPNN_DIR}/seqs/*.fa\"))\n",
    "mpnn_fasta = {k: seq.strip() for k, seq in mpnn_fasta.items() if \"model_path\" not in k}  # excluding the diffused poly-A sequence\n",
    "# Giving sequences unique names based on input PDB name, temperature, and sequence identifier\n",
    "mpnn_fasta = {k.split(\",\")[0]+\"_\"+k.split(\",\")[2].replace(\" T=\", \"T\")+\"_0_\"+k.split(\",\")[1].replace(\" id=\", \"\"): seq for k, seq in mpnn_fasta.items()}\n",
    "\n",
    "print(f\"A total on {len(mpnn_fasta)} sequences will be predicted.\")\n",
    "\n",
    "## Splitting the MPNN sequences based on length\n",
    "## Use group size of >40 when running on GPU. Also depends on how many sequences and resources you have.\n",
    "\n",
    "SEQUENCES_PER_AF2_JOB = 5  # CPU\n",
    "if USE_GPU_for_AF2 is True:\n",
    "    SEQUENCES_PER_AF2_JOB = 100  # GPU\n",
    "mpnn_fasta_split = utils.split_fasta_based_on_length(mpnn_fasta, SEQUENCES_PER_AF2_JOB, write_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2fe694-1a64-461b-af64-7d11f83285b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "\n",
    "## === Setup AlphaFold2 parameters ===\n",
    "AF2_recycles = 3\n",
    "AF2_models = \"4\"  # Add more like \"3 4 5\" if needed\n",
    "\n",
    "commands_af2 = []\n",
    "cmds_filename_af2 = \"commands_af2\"\n",
    "\n",
    "# Write all commands to file for reference\n",
    "with open(cmds_filename_af2, \"w\") as file:\n",
    "    for ff in glob.glob(\"*.fasta\"):\n",
    "        cmd = (\n",
    "            f\"{PYTHON['af2']} {AF2_script} \"\n",
    "            f\"--af-nrecycles {AF2_recycles} --af-models {AF2_models} \"\n",
    "            f\"--fasta {ff} --scorefile {ff.replace('.fasta', '.csv')}\"\n",
    "        )\n",
    "        commands_af2.append(cmd)\n",
    "        file.write(cmd + \"\\n\")\n",
    "\n",
    "print(\"Example AF2 command:\")\n",
    "print(commands_af2[-1])\n",
    "\n",
    "## === Run AlphaFold2 commands locally, one by one ===\n",
    "for cmd in commands_af2:\n",
    "    print(f\"\\nRunning locally:\\n{cmd}\\n\")\n",
    "    result = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(\"STDOUT:\\n\", result.stdout.decode())\n",
    "    print(\"STDERR:\\n\", result.stderr.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd903277-4a75-4368-a217-566209811240",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you're done with diffusion and happy with the outputs then mark it as done\n",
    "AF2_DIR = f\"{WDIR}/2_af2\"\n",
    "os.chdir(AF2_DIR)\n",
    "\n",
    "if not os.path.exists(AF2_DIR+\"/.done\"):\n",
    "    with open(f\"{AF2_DIR}/.done\", \"w\") as file:\n",
    "        file.write(f\"Run user: {username}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea32f1d-83ff-4f4f-8878-d448722f84e4",
   "metadata": {},
   "source": [
    "## Analyzing alphafold2 predictions\n",
    "\n",
    "Before proceeding, check if there are any zero vector atoms which could interfere with the analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48650cdb-ed07-4880-b7cb-fbb1d02be005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB import PDBParser\n",
    "import os\n",
    "\n",
    "folder = \"/home/projects/protein_design/binder_diffusion/2_af2/\"\n",
    "parser = PDBParser(QUIET=True)\n",
    "\n",
    "for fname in os.listdir(folder):\n",
    "    if not fname.endswith(\".pdb\"):\n",
    "        continue\n",
    "    path = os.path.join(folder, fname)\n",
    "    try:\n",
    "        structure = parser.get_structure(\"ref\", path)\n",
    "        zero_coords = False\n",
    "        for atom in structure.get_atoms():\n",
    "            if all(abs(coord) < 1e-5 for coord in atom.get_coord()):\n",
    "                zero_coords = True\n",
    "                break\n",
    "        if zero_coords:\n",
    "            print(f\"{fname} contains zero-vector atoms\")\n",
    "    except Exception as e:\n",
    "        print(f\"{fname} failed to parse: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2705a75-ad8f-4797-aced-d58a96c64d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code removes side chain atoms with 0.0 coordinatates. Modify to ensure motif residues are unaffected\n",
    "# Directory containing your PDB files\n",
    "pdb_dir = \"/home/projects/protein_design/binder_diffusion/0_diffusion/filtered_structures/\"\n",
    "\n",
    "# Go through all files in the directory\n",
    "for file_name in os.listdir(pdb_dir):\n",
    "    if file_name.lower().endswith(\".pdb\"):\n",
    "        file_path = os.path.join(pdb_dir, file_name)\n",
    "        new_lines = []\n",
    "\n",
    "        with open(file_path, 'r') as infile:\n",
    "            for line in infile:\n",
    "                if line.startswith((\"ATOM\", \"HETATM\")) and len(line) >= 54:\n",
    "                    try:\n",
    "                        x = float(line[30:38])\n",
    "                        y = float(line[38:46])\n",
    "                        z = float(line[46:54])\n",
    "                        if x == 0.0 and y == 0.0 and z == 0.0:\n",
    "                            continue  # Skip this line\n",
    "                    except ValueError:\n",
    "                        pass  # In case of parsing error, just keep the line\n",
    "                new_lines.append(line)\n",
    "\n",
    "        # Overwrite original file with cleaned content\n",
    "        with open(file_path, 'w') as outfile:\n",
    "            outfile.writelines(new_lines)\n",
    "\n",
    "        print(f\"Cleaned: {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d9d18e-1e0a-4c6b-8c3b-09b47387cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all CSV scorefiles into one\n",
    "AF2_DIR = f\"{WDIR}/2_af2\"\n",
    "DIFFUSION_DIR = f\"{WDIR}/0_diffusion\"\n",
    "\n",
    "os.system(\"head -n 1 $(ls *aa*.csv | shuf -n 1) > scores.csv ; for f in *aa*.csv ; do tail -n +2 ${f} >> scores.csv ; done\")\n",
    "assert os.path.exists(\"scores.csv\"), \"Could not combine scorefiles\"\n",
    "\n",
    "### Calculating the RMSDs of AF2 predictions relative to the diffusion outputs\n",
    "### Catalytic residue sidechain RMSDs are calculated in the reference PDB has REMARK 666 line present\n",
    "\n",
    "analysis_cmd = f\"{PYTHON['general']} {SCRIPT_DIR}/scripts/utils/analyze_af2.py --scorefile scores.csv \"\\\n",
    "               f\"--ref_path {DIFFUSION_DIR}/filtered_structures --mpnn --params {' '.join(params)}\"\n",
    "\n",
    "\n",
    "if len(glob.glob(f\"{AF2_DIR}/*.pdb\")) > 100:\n",
    "    ## Analyzing locally\n",
    "    p = subprocess.Popen(analysis_cmd, shell=True)\n",
    "    (output, err) = p.communicate()\n",
    "else:\n",
    "    ## Running as a Slurm job\n",
    "    submit_script = \"submit_af2_analysis.sh\"\n",
    "    utils.create_slurm_submit_script(filename=submit_script, name=\"af2_analysis\",\n",
    "                                     mem=\"16g\", N_cores=8, time=\"0:20:00\", email=EMAIL,\n",
    "                                     command=analysis_cmd, outfile_name=\"output_analysis\")\n",
    "\n",
    "    p = subprocess.Popen([\"sbatch\", submit_script])\n",
    "    (output, err) = p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc897b5-cb06-4a63-915b-9b721c33139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This plots out the model ouput\n",
    "## There is a seperate notebook for a more visually appealing plot used for my poster\n",
    "scores_af2 = pd.read_csv(\"scores.sc\", sep=\"\\s+\", header=0)\n",
    "\n",
    "### Filtering AF2 scores based on lddt and rmsd\n",
    "# Define your desired cutoffs here:\n",
    "AF2_filters = {\"lDDT\": [80.0, \">=\"],\n",
    "               \"rmsd\": [2.0, \"<=\"]}  # 1st catalytic residue sc-rmsd\n",
    "\n",
    "scores_af2_filtered = utils.filter_scores(scores_af2, AF2_filters)\n",
    "utils.dump_scorefile(scores_af2_filtered, \"filtered_scores.sc\")\n",
    "\n",
    "## Plotting AF2 scores\n",
    "plt.figure(figsize=(12, 3))\n",
    "for i,k in enumerate(AF2_filters):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.hist(scores_af2[k])\n",
    "    plt.title(k)\n",
    "    plt.xlabel(k)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "utils.plot_score_pairs(scores_af2, \"lDDT\", \"rmsd\", AF2_filters[\"lDDT\"][0], AF2_filters[\"rmsd\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfd48a6-afa1-4044-9b32-8338c6ab9b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Copying good predictions to a separate directory\n",
    "## This step is important to add hydrogens and have a complete structure. However pyrosetta tries to add an amino acid as the ligand instead of technetium. Manually remove this\n",
    "## Superimpose the designs from this step with the generated backbone to have the tc complex back in the structure \n",
    "os.chdir(AF2_DIR)\n",
    "\n",
    "if len(scores_af2_filtered) > 0:\n",
    "    os.makedirs(\"good\", exist_ok=True)\n",
    "    good_af2_models = [row[\"Output_PDB\"]+\".pdb\" for idx,row in scores_af2_filtered.iterrows()]\n",
    "    for pdb in good_af2_models:\n",
    "        copy2(pdb, f\"good/{pdb}\")\n",
    "    good_af2_models = glob.glob(f\"{AF2_DIR}/good/*.pdb\")\n",
    "else:\n",
    "    sys.exit(\"No good models to continue this pipeline with\")\n",
    "\n",
    "os.chdir(f\"{AF2_DIR}/good\")\n",
    "\n",
    "\n",
    "### Aligning the ligand back into the AF2 predictions.\n",
    "### This is done by aligning the AF2 model to diffusion output and copying over the ligand using PyRosetta.\n",
    "### --fix_catres option will readjust the rotamer and tautomer of \n",
    "### any catalytic residue to be the same as in the reference model.\n",
    "\n",
    "align_cmd = f\"{PYTHON['general']} {SCRIPT_DIR}/scripts/utils/place_ligand_after_af2.py \"\\\n",
    "            f\"--outdir with_heme2 --params {' '.join(params)} --fix_catres \"\\\n",
    "            f\"--pdb {' '.join(good_af2_models)} \"\\\n",
    "            f\"--ref {' '.join(glob.glob(DIFFUSION_DIR+'/filtered_structures/*.pdb'))}\"\n",
    "\n",
    "p = subprocess.Popen(align_cmd, shell=True)\n",
    "(output, err) = p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4dead6-ce17-4754-bcc4-21c9f1356404",
   "metadata": {},
   "outputs": [],
   "source": [
    "##END Subs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
